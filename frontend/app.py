import streamlit as st
import requests
import base64
import io
import json
import time
import pandas as pd
import matplotlib.pyplot as plt
import cv2
import os
import tempfile
import base64
import google.generativeai as genai
from PIL import Image
from ultralytics import YOLO
from dotenv import load_dotenv
from streamlit_option_menu import option_menu

load_dotenv()
GEMINI_KEY = os.getenv("GEMINI_API_KEY")
if GEMINI_KEY:
    try:
        genai.configure(api_key=GEMINI_KEY)
    except Exception:
        # proceed: genai may still error at call time
        pass

st.set_page_config(page_title="Agri Vision - H·ªá Th·ªëng Nh·∫≠n D·∫°ng Vfa Ph√¢n Lo·∫°i ƒê·ªô Ch√≠n Tr√°i M√≠t", layout="wide")
st.markdown(
    """
    <style>
    .main-title {
        font-size: 20px;
        font-weight: 800;
        text-align: center;
        color: #2E7D32;
        margin-bottom: 0.3em;
        letter-spacing: 0.5px;
    }
    .sub-title {
        text-align: center;
        font-size: 18px;
        color: #555;
        font-style: italic;
        margin-bottom: 1.5em;
    }
    hr {
        border: none;
        height: 2px;
        background: linear-gradient(to right, #8BC34A, #558B2F);
        margin-bottom: 1.5em;
    }
    </style>
    
    <div class="main-title">AGRI VISION ‚Äî H·ªÜ TH·ªêNG NH·∫¨N D·∫†NG V√Ä PH√ÇN LO·∫†I ƒê·ªò CH√çN TR√ÅI M√çT</div>
    <p class="sub-title">·ª®ng d·ª•ng AI ph·ª•c v·ª• N√¥ng nghi·ªáp Th√¥ng minh üåæ</p>
    <hr>
    """,
    unsafe_allow_html=True
)

ROOT = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
API_URL = "http://127.0.0.1:8000/predict"
LATEST_RESULTS = os.path.join(os.path.dirname(__file__), "latest_results.json")

# --- Chuy·ªÉn ·∫£nh logo sang base64 ƒë·ªÉ hi·ªÉn th·ªã ---
def get_base64_of_bin_file(bin_file):
    with open(bin_file, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()

logo_path = os.path.join(os.path.dirname(__file__), "logo.png")
if os.path.exists(logo_path):
    logo_base64 = get_base64_of_bin_file(logo_path)
    logo_html = f'<img src="data:image/png;base64,{logo_base64}" width="140" style="border-radius:10px; margin-bottom:10px"/>'
else:
    logo_html = "<div style='font-size:40px'>üçà</div>"


theme = st.get_option("theme.base")  # tr·∫£ v·ªÅ 'dark' ho·∫∑c 'light'

if theme == "dark":
    menu_styles = {
        "container": {
            "background-color": "#1C1E24",
            "padding": "1rem",
            "border-radius": "12px",
        },
        "icon": {"color": "#FFFFFF", "font-size": "20px"},
        "nav-link": {
            "font-size": "16px",
            "color": "#FFFFFFCC",
            "text-align": "left",
            "margin": "6px 0",
            "--hover-color": "#292B33",
            "border-radius": "8px",
        },
        "nav-link-selected": {
            "background-color": "#6DBE45",
            "color": "#FFFFFF",
            "font-weight": "600",
        },
    }
else:
    menu_styles = {
        "container": {
            "background-color": "#FFFFFF",
            "padding": "1rem",
            "border-radius": "12px",
            "box-shadow": "0 2px 8px rgba(0,0,0,0.05)",
        },
        "icon": {"color": "#8EEB60", "font-size": "20px"},
        "nav-link": {
            "font-size": "16px",
            "color": "#000000CC",
            "text-align": "left",
            "margin": "6px 0",
            "--hover-color": "#E8F5E9",
            "border-radius": "8px",
        },
        "nav-link-selected": {
            "background-color": "#6DBE45",
            "color": "#FFFFFF",
            "font-weight": "600",
        },
    }
# Sidebar logo + menu
with st.sidebar:
    st.markdown(
        f"""
        <div style="text-align:center; padding-bottom:10px">
             {logo_html}
        </div>
        """,
        unsafe_allow_html=True,
    )

    choice = option_menu(
        None,
        ["Trang ch·ªß", "Ph√¢n t√≠ch ·∫£nh", "Video/Webcam",
         "Th·ªëng k√™", "So s√°nh YOLOv8", "Chat AgriVision "],
        icons=["house", "camera", "camera-video", "bar-chart", "activity", "chat-dots"],
        default_index=1,
        styles=menu_styles,
    )
    #Reset session_state khi chuy·ªÉn tab ƒë·ªÉ tr√°nh l·ªói hi·ªÉn th·ªã ch·ªìng
    if "last_tab" not in st.session_state:
        st.session_state["last_tab"] = choice
    elif st.session_state["last_tab"] != choice:
    # Reset tr·∫°ng th√°i ch·ªâ khi ƒë·ªïi tab
        st.session_state["last_tab"] = choice
        st.session_state.pop("video_done", None)
        st.session_state.pop("video_json", None)
        st.session_state.pop("last_data", None)

if choice == "Trang ch·ªß":
    st.markdown("""
    ### üéØ M·ª•c ti√™u d·ª± √°n
    ·ª®ng d·ª•ng AI gi√∫p n√¥ng d√¢n nh·∫≠n bi·∫øt **ƒë·ªô ch√≠n c·ªßa tr√°i m√≠t** qua h√¨nh ·∫£nh, 
    h·ªó tr·ª£ **ra quy·∫øt ƒë·ªãnh thu ho·∫°ch ch√≠nh x√°c**, gi·∫£m th·∫•t tho√°t, 
    h∆∞·ªõng ƒë·∫øn **n√¥ng nghi·ªáp th√¥ng minh**.
    """)
    st.info("Ch·ªçn m·ª•c trong menu b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu üëâ")

# ---------------- TAB 1: ·∫¢NH ----------------
elif choice == "Ph√¢n t√≠ch ·∫£nh":
    st.header("Ph√¢n t√≠ch ·∫£nh")

    # === Khu v·ª±c upload v√† ch·ªçn ng∆∞·ª°ng ===
    with st.container():
        st.markdown("### üñºÔ∏è Ch·ªçn ·∫£nh tr√°i m√≠t c·∫ßn ph√¢n t√≠ch")
        uploaded_file = st.file_uploader("üìÅ T·∫£i ·∫£nh l√™n (JPG, JPEG, PNG)", type=["jpg", "jpeg", "png"])
        confidence = st.slider("Ng∆∞·ª°ng Confidence",0.1, 1.0, 0.5, 0.05,help="Gi√° tr·ªã n√†y x√°c ƒë·ªãnh m·ª©c ƒë·ªô ch·∫Øc ch·∫Øn c·ªßa m√¥ h√¨nh khi nh·∫≠n d·∫°ng. "
         "C√†ng cao th√¨ m√¥ h√¨nh ch·ªâ hi·ªÉn th·ªã c√°c ƒë·ªëi t∆∞·ª£ng m√† n√≥ tin t∆∞·ªüng m·∫°nh, "
         "c√†ng th·∫•p th√¨ m√¥ h√¨nh hi·ªÉn th·ªã nhi·ªÅu h∆°n nh∆∞ng d·ªÖ nhi·ªÖu.")
        st.markdown("<br>", unsafe_allow_html=True)
        analyze_btn = st.button("üîç B·∫Øt ƒë·∫ßu ph√¢n t√≠ch ·∫£nh", use_container_width=True)

    # --- Hi·ªÉn th·ªã ·∫£nh g·ªëc v√† ·∫£nh k·∫øt qu·∫£ ngang h√†ng ---
    if uploaded_file:
        col1, col2 = st.columns(2)
        img = Image.open(uploaded_file).convert("RGB")
        with col1:
            st.markdown("**·∫¢nh g·ªëc**")
            st.image(img, use_container_width=True)
        with col2:
            st.markdown("**·∫¢nh k·∫øt qu·∫£ nh·∫≠n d·∫°ng**")
            out_image = st.empty()

    # === Khi nh·∫•n n√∫t "Ph√¢n t√≠ch ·∫£nh" ===
    if analyze_btn and uploaded_file:
        status_placeholder = st.empty()
        status_placeholder.info("‚è≥ ƒêang x·ª≠ l√Ω ·∫£nh, vui l√≤ng ch·ªù trong gi√¢y l√°t...")
        progress = st.progress(0)
        files = {"file": uploaded_file.getvalue()}

        try:
            for percent in range(0, 80, 10):
                time.sleep(0.1)
                progress.progress(percent)

            resp = requests.post(API_URL, files=files, params={"conf": confidence}, timeout=30)
            resp.raise_for_status()
            data = resp.json()

            for percent in range(80, 101, 10):
                time.sleep(0.1)
                progress.progress(percent)

        except Exception as e:
            st.error(f"L·ªói g·ªçi API: {e}")
            data = None

        progress.empty()
        status_placeholder.empty()
        st.success("‚ú® Ph√¢n t√≠ch ho√†n t·∫•t!")

        # --- Hi·ªÉn th·ªã k·∫øt qu·∫£ ---
        if data:
            img_data = base64.b64decode(data["image"])
            annotated = Image.open(io.BytesIO(img_data)).convert("RGB")
            st.session_state.last_data = data
            st.session_state.last_img = annotated

            # c·∫≠p nh·∫≠t ·∫£nh k·∫øt qu·∫£ b√™n ph·∫£i
            out_image.image(annotated, use_container_width=True)

            detections = data.get("detections", [])
            if not detections:
                st.warning("‚ö†Ô∏è Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c tr√°i m√≠t n√†o.")
            else:
                df = pd.DataFrame(detections)
                row_df = (
                    df[["label", "confidence"]]
                    .rename(columns={"label": "Lo·∫°i", "confidence": "ƒê·ªô tin c·∫≠y"})
                    .copy()
                )

                row_df["ƒê·ªô tin c·∫≠y"] = row_df["ƒê·ªô tin c·∫≠y"].map(lambda x: f"{x:.2f}")


                st.markdown("---")
                st.markdown("### üìä K·∫øt qu·∫£ nh·∫≠n d·∫°ng")
                st.dataframe(
                    row_df.style.set_properties(**{
                        'text-align': 'center',
                        'font-size': '16px'
                    })
                )

    # === PH·∫¶N 2: Ph√¢n t√≠ch AI chuy√™n s√¢u ===
    if "last_data" in st.session_state:
        st.markdown("---")
        st.markdown("""
        <div style='background-color:#F9FBE7; padding:15px; border-radius:10px;'>
            <h4 style='color:#33691E;'>üß† Ph√¢n t√≠ch ·∫£nh chuy√™n s√¢u b·ªüi AgriVision</h4>
            <p style='color:#4E342E;'>AI h·ªó tr·ª£ ƒë√°nh gi√° ƒë·ªô ch√≠n, s√¢u b·ªánh v√† khuy·∫øn ngh·ªã thu ho·∫°ch.</p>
        </div>
        """, unsafe_allow_html=True)

        def summarize_counts_from_latest(latest: dict):
            preds = latest.get("predictions")
            if isinstance(preds, list):
                counts = {}
                for p in preds:
                    cls = p.get("class")
                    if cls:
                        counts[cls] = counts.get(cls, 0) + 1
                total = sum(counts.values())
                return counts, total
            counts = latest.get("counts", {}) or {}
            total = latest.get("total", sum(counts.values()))
            return counts, total

        if os.path.exists(LATEST_RESULTS):
            with open(LATEST_RESULTS, "r", encoding="utf-8") as f:
                last = json.load(f)
            
            st.markdown("<div style='margin-top:15px'></div>", unsafe_allow_html=True)
            with st.expander("üì¶ Xem d·ªØ li·ªáu ƒë·∫ßu v√†o t·ª´ h·ªá th·ªëng nh·∫≠n d·∫°ng"):
                st.json(last)

            counts, total = summarize_counts_from_latest(last)

            if st.button("üìä Y√™u c·∫ßu AgriVision ph√¢n t√≠ch ·∫£nh", use_container_width=True):
                status_placeholder = st.empty()
                status_placeholder.info("ü§ñ AgriVision ƒëang ph√¢n t√≠ch d·ªØ li·ªáu t·ª´ h√¨nh ·∫£nh, vui l√≤ng ch·ªù...")
                progress = st.progress(0)

                for p in range(0, 100, 10):
                    time.sleep(0.1)
                    progress.progress(p)

                prompt = f"""
                B·∫°n l√† h·ªá th·ªëng AgriVision ‚Äî n·ªÅn t·∫£ng AI ·ª©ng d·ª•ng YOLOv8 trong nh·∫≠n d·∫°ng v√† ph√¢n lo·∫°i ƒë·ªô ch√≠n tr√°i m√≠t.Sau m·ªói l·∫ßn x·ª≠ l√Ω h√¨nh ·∫£nh, b·∫°n s·∫Ω t·ª± ƒë·ªông t·∫°o K·∫øt qu·∫£ ph√¢n t√≠ch t·ªïng h·ª£p k·∫øt qu·∫£ ph√¢n t√≠ch.  
                D·ªØ li·ªáu ƒë·∫ßu v√†o b·∫°n v·ª´a x·ª≠ l√Ω:
                counts={counts}, total={total}.
                H√£y vi·∫øt **K·∫øt qu·∫£ ph√¢n t√≠ch  t·ª± nhi√™n, g·∫ßn g≈©i nh∆∞ng chuy√™n nghi·ªáp**, th·ªÉ hi·ªán ƒë∆∞·ª£c nƒÉng l·ª±c c√¥ng ngh·ªá c·ªßa h·ªá th·ªëng AgriVision.  
                Gi·ªçng vƒÉn gi·ªëng nh∆∞ m·ªôt k·ªπ s∆∞ n√¥ng nghi·ªáp ƒëang chia s·∫ª l·∫°i k·∫øt qu·∫£ m√† AgriVision v·ª´a quan s√°t ƒë∆∞·ª£c.
                B·ªë c·ª•c y√™u c·∫ßu:
                1) T·ªïng quan t√¨nh h√¨nh nh·∫≠n d·∫°ng (k·∫øt qu·∫£ ph√°t hi·ªán, t·ªâ l·ªá m√≠t ch√≠n, non, s√¢u b·ªánh).  
                2Ô∏è) Nh·∫≠n x√©t & khuy·∫øn ngh·ªã thu ho·∫°ch (n√™u r√µ n√™n thu hay ch∆∞a, l√Ω do, l·ª£i √≠ch).  
                3Ô∏è) Bi·ªán ph√°p x·ª≠ l√Ω n·∫øu c√≥ m√≠t s√¢u b·ªánh (ƒë∆∞a h∆∞·ªõng d·∫´n th·ª±c t·∫ø, d·ªÖ hi·ªÉu).  
                4Ô∏è) H·ªó tr·ª£ k·ªπ thu·∫≠t & t√≠nh nƒÉng th√¥ng minh c·ªßa h·ªá th·ªëng (m√¥ t·∫£ c√°ch AgriVision gi√∫p ng∆∞·ªùi d√πng qu·∫£n l√Ω v√† chƒÉm s√≥c v∆∞·ªùn hi·ªáu qu·∫£ h∆°n).   
                5) Gi·ªõi thi·ªáu ng·∫Øn v·ªÅ vai tr√≤ c·ªßa AgriVision trong vi·ªác h·ªó tr·ª£ b·∫°n theo d√µi v∆∞·ªùn qua h√¨nh ·∫£nh.
                
                Phong c√°ch vi·∫øt:
                - M·ªü ƒë·∫ßu b·∫±ng l·ªùi ch√†o: ‚ÄúCh√†o b·∫°n, t√¥i l√† AgriVision ‚Äì ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh trong v∆∞·ªùn m√≠t.‚Äù  
                - Ng√¥n t·ª´ th√¢n thi·ªán, r√µ r√†ng, kh√¥ng r∆∞·ªùm r√†.  
                """

                ai_text = None
                try:
                    if GEMINI_KEY:
                        model = genai.GenerativeModel("models/gemini-2.5-flash")
                        resp = model.generate_content(prompt)
                        ai_text = getattr(resp, "text", None) or str(resp)
                    else:
                        raise RuntimeError("No GEMINI key")
                except Exception as e:
                    ai_text = None
                    st.error(f"Kh√¥ng g·ªçi ƒë∆∞·ª£c Gemini (fallback). L·ªói: {e}")

                progress.empty()
                status_placeholder.empty()
                st.success("‚ú® Ph√¢n t√≠ch ho√†n t·∫•t!")

                if not ai_text:
                    lines = ["B√°o c√°o ph√¢n t√≠ch (fallback):"]
                    if total == 0:
                        lines.append("- Kh√¥ng ph√°t hi·ªán tr√°i m√≠t n√†o trong ·∫£nh.")
                    else:
                        for k, v in counts.items():
                            pct = (v / total) * 100 if total > 0 else 0
                            lines.append(f"- {k}: {v} tr√°i ({pct:.1f}%)")
                    ai_text = "\n".join(lines)

                st.markdown("### üìë K·∫øt qu·∫£ ph√¢n t√≠ch AI")
                st.markdown(
                    f"<div style='background-color:#FAFAFA; padding:15px; border-radius:10px; color:#212121;'>{ai_text}</div>",
                    unsafe_allow_html=True
                )

# ---------------- TAB 2: VIDEO / WEBCAM ----------------
elif choice == "Video/Webcam":
    import time, json, tempfile, os, cv2
    from ultralytics import YOLO

    st.markdown("## üé• Ph√¢n t√≠ch Video / Webcam")
    st.info(
        "ü§ñ **AgriVision** nh·∫≠n d·∫°ng ƒë·ªô ch√≠n tr√°i m√≠t tr·ª±c ti·∫øp t·ª´ video ho·∫∑c webcam. "
        "Video ƒë∆∞·ª£c x·ª≠ l√Ω b·∫±ng m√¥ h√¨nh YOLOv8, hi·ªÉn th·ªã bounding box, label v√† JSON realtime b√™n c·∫°nh."
    )

    # --- T·∫£i model ---
    @st.cache_resource(show_spinner="üöÄ ƒêang t·∫£i m√¥ h√¨nh YOLOv8...")
    def load_model():
        model_path = os.path.join(os.path.dirname(__file__), "..", "yolov8", "best.pt")
        return YOLO(model_path)

    model = load_model()

    # --- C·∫•u h√¨nh ---
    st.markdown("---")
    col1, col2 = st.columns(2)
    with col1:
        source = st.radio("Ngu·ªìn d·ªØ li·ªáu:", ["üéûÔ∏è Video file", "üì∑ Webcam"], horizontal=True)
    with col2:
        conf_v = st.slider("Ng∆∞·ª°ng Confidence",0.1, 1.0, 0.5, 0.05,
        help="Gi√° tr·ªã n√†y x√°c ƒë·ªãnh m·ª©c ƒë·ªô ch·∫Øc ch·∫Øn c·ªßa m√¥ h√¨nh khi nh·∫≠n d·∫°ng. "
         "C√†ng cao th√¨ m√¥ h√¨nh ch·ªâ hi·ªÉn th·ªã c√°c ƒë·ªëi t∆∞·ª£ng m√† n√≥ tin t∆∞·ªüng m·∫°nh, "
         "c√†ng th·∫•p th√¨ m√¥ h√¨nh hi·ªÉn th·ªã nhi·ªÅu h∆°n nh∆∞ng d·ªÖ nhi·ªÖu."
)

    st.markdown("---")
    if source == "üì∑ Webcam":
        st.session_state["video_done"] = False
        st.session_state.pop("video_json", None)


    # ------------------- VIDEO FILE -------------------
    if source == "üéûÔ∏è Video file":
        uploaded = st.file_uploader("üìÅ T·∫£i video l√™n (MP4, MOV, AVI)", type=["mp4", "mov", "avi"])

        if uploaded:
            temp_input = tempfile.NamedTemporaryFile(delete=False, suffix=".mp4")
            temp_input.write(uploaded.read())
            video_path = temp_input.name

            st.video(video_path)
            st.success("‚úÖ Video ƒë√£ t·∫£i xong! B·∫•m n√∫t d∆∞·ªõi ƒë·ªÉ b·∫Øt ƒë·∫ßu ph√¢n t√≠ch.")

            if st.button("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu ph√¢n t√≠ch video"):
                cap = cv2.VideoCapture(video_path)
                fps = int(cap.get(cv2.CAP_PROP_FPS)) or 24

                video_col, json_col = st.columns([3, 2])
                frame_slot = video_col.empty()
                json_box = json_col.empty()
                detections_all = []

                while cap.isOpened():
                    ret, frame = cap.read()
                    if not ret:
                        break

                    results = model.track(frame, conf=conf_v, persist=True, tracker="bytetrack.yaml")
                    predictions_json = {"predictions": []}

                    if results and len(results) > 0:
                        boxes = results[0].boxes
                        labels = results[0].names
                        for box in boxes:
                            cls_id = int(box.cls[0])
                            label = labels.get(cls_id, "m√≠t")
                            conf = float(box.conf[0])
                            xyxy = box.xyxy[0].cpu().numpy().astype(float)
                            x, y, w, h = xyxy[0], xyxy[1], xyxy[2] - xyxy[0], xyxy[3] - xyxy[1]

                            predictions_json["predictions"].append({
                                "class": label,
                                "confidence": round(conf, 3),
                                "bbox": {
                                    "x": round(x, 3),
                                    "y": round(y, 3),
                                    "width": round(w, 3),
                                    "height": round(h, 3)
                                }
                            })

                            # V·∫Ω khung v√† nh√£n
                            cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])),
                                          (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)
                            label_text = f"{label} {conf:.0%}"
                            (tw, th), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
                            cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1] - th - 6)),
                                          (int(xyxy[0] + tw + 4), int(xyxy[1])), (0, 255, 0), -1)
                            cv2.putText(frame, label_text, (int(xyxy[0] + 2), int(xyxy[1] - 4)),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

                    # Hi·ªÉn th·ªã realtime
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    frame_slot.image(frame_rgb, use_container_width=True)

                    # JSON realtime b√™n ph·∫£i
                    json_html = f"""
                    <div style='background-color:#f9fafb;padding:10px;border-radius:10px;
                    border:1px solid #e3e3e3;height:308px;overflow-y:auto;
                    font-family:monospace;font-size:13px;white-space:pre;'>
                        {json.dumps(predictions_json, indent=2, ensure_ascii=False)}
                    </div>
                    """
                    json_box.markdown(json_html, unsafe_allow_html=True)
                    detections_all.append(predictions_json)

                cap.release()

                # L∆∞u k·∫øt qu·∫£ cu·ªëi c√πng
                st.session_state["video_done"] = True
                st.session_state["video_json"] = detections_all[-1] if detections_all else {}
    # ---------------- SAU KHI X·ª¨ L√ù XONG VIDEO ----------------
    if st.session_state.get("video_done", False):
        latest = st.session_state.get("video_json", {})

        st.markdown("---")
        st.markdown("""
        <div style='background-color:#FCFCE3; padding:15px; border-radius:10px; margin-bottom:10px;'>
            <h4 style='color:#33691E;'>üí¨ Ph√¢n t√≠ch video chuy√™n s√¢u b·ªüi AgriVision</h4>
            <p style='color:#4E342E;'>AgriVision t·ªïng h·ª£p v√† ƒë√°nh gi√° k·∫øt qu·∫£ nh·∫≠n d·∫°ng t·ª´ video b·∫°n g·ª≠i.</p>
        </div>
        """, unsafe_allow_html=True)

        def summarize_video_data(data):
            preds = data.get("predictions", [])
            counts = {}
            for p in preds:
                cls = p.get("class")
                if cls:
                    counts[cls] = counts.get(cls, 0) + 1
            total = sum(counts.values())
            return counts, total

        counts, total = summarize_video_data(latest)

        if st.button("üìä Y√™u c·∫ßu AgriVision ph√¢n t√≠ch video", use_container_width=True):
            status = st.empty()
            progress = st.progress(0)
            status.info("ü§ñ AgriVision ƒëang ph√¢n t√≠ch d·ªØ li·ªáu video...")
            for p in range(0, 100, 10):
                time.sleep(0.1)
                progress.progress(p)
            progress.empty()
            status.empty()

            prompt = f"""
            B·∫°n l√† h·ªá th·ªëng AgriVision ‚Äî n·ªÅn t·∫£ng AI ·ª©ng d·ª•ng YOLOv8 trong nh·∫≠n d·∫°ng v√† ph√¢n lo·∫°i ƒë·ªô ch√≠n tr√°i m√≠t.Sau m·ªói l·∫ßn x·ª≠ l√Ω video, b·∫°n s·∫Ω t·ª± ƒë·ªông t·∫°o K·∫øt qu·∫£ ph√¢n t√≠ch t·ªïng h·ª£p k·∫øt qu·∫£ ph√¢n t√≠ch.  
            D·ªØ li·ªáu ƒë·∫ßu v√†o b·∫°n v·ª´a x·ª≠ l√Ω:
            counts={counts}, total={total}.
            H√£y vi·∫øt **K·∫øt qu·∫£ ph√¢n t√≠ch  t·ª± nhi√™n, g·∫ßn g≈©i nh∆∞ng chuy√™n nghi·ªáp**, th·ªÉ hi·ªán ƒë∆∞·ª£c nƒÉng l·ª±c c√¥ng ngh·ªá c·ªßa h·ªá th·ªëng AgriVision.  
            Gi·ªçng vƒÉn gi·ªëng nh∆∞ m·ªôt k·ªπ s∆∞ n√¥ng nghi·ªáp ƒëang chia s·∫ª l·∫°i k·∫øt qu·∫£ m√† AgriVision v·ª´a quan s√°t ƒë∆∞·ª£c.
            B·ªë c·ª•c y√™u c·∫ßu:
            1) T·ªïng quan t√¨nh h√¨nh nh·∫≠n d·∫°ng (k·∫øt qu·∫£ ph√°t hi·ªán, t·ªâ l·ªá m√≠t ch√≠n, non, s√¢u b·ªánh).  
            2Ô∏è) Nh·∫≠n x√©t & khuy·∫øn ngh·ªã thu ho·∫°ch (n√™u r√µ n√™n thu hay ch∆∞a, l√Ω do, l·ª£i √≠ch).  
            3Ô∏è) Bi·ªán ph√°p x·ª≠ l√Ω n·∫øu c√≥ m√≠t s√¢u b·ªánh (ƒë∆∞a h∆∞·ªõng d·∫´n th·ª±c t·∫ø, d·ªÖ hi·ªÉu).  
            4Ô∏è) H·ªó tr·ª£ k·ªπ thu·∫≠t & t√≠nh nƒÉng th√¥ng minh c·ªßa h·ªá th·ªëng (m√¥ t·∫£ c√°ch AgriVision gi√∫p ng∆∞·ªùi d√πng qu·∫£n l√Ω v√† chƒÉm s√≥c v∆∞·ªùn hi·ªáu qu·∫£ h∆°n).   
            5) Gi·ªõi thi·ªáu ng·∫Øn v·ªÅ vai tr√≤ c·ªßa AgriVision trong vi·ªác h·ªó tr·ª£ b·∫°n theo d√µi v∆∞·ªùn qua video.  
            Phong c√°ch vi·∫øt:
            - M·ªü ƒë·∫ßu b·∫±ng l·ªùi ch√†o: ‚ÄúCh√†o b·∫°n, t√¥i l√† AgriVision ‚Äì ng∆∞·ªùi b·∫°n ƒë·ªìng h√†nh trong v∆∞·ªùn m√≠t.‚Äù  
            - Ng√¥n t·ª´ th√¢n thi·ªán, r√µ r√†ng, kh√¥ng r∆∞·ªùm r√†.  
            """

            ai_text = None
            try:
                if GEMINI_KEY:
                    model = genai.GenerativeModel("models/gemini-2.5-flash")
                    resp = model.generate_content(prompt)
                    ai_text = getattr(resp, "text", None) or str(resp)
                else:
                    ai_text = "Ph√¢n t√≠ch th·ªß c√¥ng: AgriVision ch∆∞a k√≠ch ho·∫°t Gemini API."
            except Exception:
                ai_text = "Kh√¥ng th·ªÉ g·ªçi Gemini API, hi·ªÉn th·ªã k·∫øt qu·∫£ t√≥m t·∫Øt thay th·∫ø."

            st.markdown("### üß† K·∫øt qu·∫£ ph√¢n t√≠ch video")
            st.markdown(
                f"<div style='background-color:#FAFAFA; padding:15px; border-radius:10px; color:#212121;'>{ai_text}</div>",
                unsafe_allow_html=True
            )
    
    # ------------------- WEBCAM (CHU·∫®N HI·ªÇN TH·ªä) -------------------
    if source == "üì∑ Webcam":
        st.info("B·∫≠t webcam c·ªßa b·∫°n ƒë·ªÉ AgriVision nh·∫≠n d·∫°ng tr√°i m√≠t theo th·ªùi gian th·ª±c.")
        run = st.checkbox("‚ñ∂Ô∏è B·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng qua Webcam", value=False)

        video_col, json_col = st.columns([3, 2])
        frame_slot = video_col.empty()
        json_box = json_col.empty()

        detections_all = []
        cap = cv2.VideoCapture(0)

        if run:
            st.warning("‚èπ D·ª´ng nh·∫≠n d·∫°ng b·∫±ng c√°ch b·ªè ch·ªçn checkbox.")
            while True:
                ret, frame = cap.read()
                if not ret or not run:
                    break

                results = model.predict(frame, conf=conf_v)
                predictions_json = {"predictions": []}

                if results and len(results) > 0:
                    boxes = results[0].boxes
                    labels = results[0].names
                    for box in boxes:
                        cls_id = int(box.cls[0])
                        label = labels.get(cls_id, "m√≠t")
                        conf = float(box.conf[0])
                        xyxy = box.xyxy[0].cpu().numpy().astype(float)
                        x, y, w, h = xyxy[0], xyxy[1], xyxy[2] - xyxy[0], xyxy[3] - xyxy[1]

                        predictions_json["predictions"].append({
                            "class": label,
                            "confidence": round(conf, 3),
                            "bbox": {
                                "x": round(x, 3),
                                "y": round(y, 3),
                                "width": round(w, 3),
                                "height": round(h, 3)
                            }
                        })

                        # V·∫Ω bounding box v√† label
                        cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1])),
                                    (int(xyxy[2]), int(xyxy[3])), (0, 255, 0), 2)
                        label_text = f"{label} {conf:.0%}"
                        (tw, th), _ = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)
                        cv2.rectangle(frame, (int(xyxy[0]), int(xyxy[1] - th - 6)),
                                    (int(xyxy[0] + tw + 4), int(xyxy[1])), (0, 255, 0), -1)
                        cv2.putText(frame, label_text, (int(xyxy[0] + 2), int(xyxy[1] - 4)),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2)

                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                frame_slot.image(frame_rgb, use_container_width=True)

                # Hi·ªÉn th·ªã JSON realtime b√™n ph·∫£i
                formatted_json = json.dumps(predictions_json, indent=2, ensure_ascii=False)
                json_box.markdown(
                    f"""
                    <div style="background-color:#f9fafb;padding:10px;border-radius:10px;
                    border:1px solid #e3e3e3;height:411px;overflow-y:auto;
                    font-family:monospace;font-size:13px;white-space:pre;">
                    {formatted_json}
                    </div>
                    """,
                    unsafe_allow_html=True
                )

                detections_all.append(predictions_json)
                time.sleep(0.05)  # ƒë·ªÉ Streamlit k·ªãp render l·∫°i UI

            cap.release()
            st.success("üü¢ Webcam ƒë√£ d·ª´ng.")

# ---------------- TAB 3: M√î H√åNH & TH·ªêNG K√ä ----------------
elif choice == "Th·ªëng k√™":
    st.header("M√¥ h√¨nh & Th·ªëng k√™")
    st.markdown("""
    **M√¥ h√¨nh hi·ªÉn th·ªã:** M√¥ h√¨nh YOLOv8 nh·∫≠n d·∫°ng m√≠t ch√≠n  
    **T·∫≠p d·ªØ li·ªáu:** ~1700 ·∫£nh, 3 nh√£n: mit_non, mit_chin, mit_saubenh  
    **Tri·ªÉn khai:** FastAPI (inference) + Streamlit (frontend)  
    """)
    st.markdown("B·∫°n c√≥ th·ªÉ m·ªü tab So s√°nh ƒë·ªÉ xem k·∫øt qu·∫£ training (results_n.csv / results_s.csv).")

# ---------------- TAB 4: So s√°nh ----------------
elif choice == "So s√°nh YOLOv8":
    st.header("So s√°nh YOLOv8n vs YOLOv8s")
    path_n = os.path.join(os.path.dirname(__file__), "..", "yolov8", "results_n.csv")
    path_s = os.path.join(os.path.dirname(__file__), "..", "yolov8", "results_s.csv")
    if os.path.exists(path_n) and os.path.exists(path_s):
        df_n = pd.read_csv(path_n)
        df_s = pd.read_csv(path_s)
        metrics = ["metrics/precision(B)", "metrics/recall(B)", "metrics/mAP50(B)"]
        for m in metrics:
            if m in df_n.columns and m in df_s.columns:
                fig, ax = plt.subplots()
                ax.plot(df_n.index, df_n[m], label="n")
                ax.plot(df_s.index, df_s[m], label="s")
                ax.set_title(m)
                ax.legend()
                st.pyplot(fig)
        st.dataframe({
            "YOLOv8n (last)": df_n.iloc[-1].to_dict(),
            "YOLOv8s (last)": df_s.iloc[-1].to_dict()
        })
    else:
        st.warning("Thi·∫øu results_n.csv / results_s.csv trong yolov8/ ‚Äî export t·ª´ qu√° tr√¨nh training.")

# ---------------- TAB 5: CHAT (Gemini) ----------------
elif choice == "Chat AgriVision ":
    st.header("Tr·ª£ l√Ω n√¥ng nghi·ªáp th√¥ng minh - AgriVision üåæ")
    st.subheader("Trao ƒë·ªïi v·ªÅ m√¥ h√¨nh YOLOv8, ƒë·ªô ch√≠n tr√°i m√≠t, ho·∫∑c k·ªπ thu·∫≠t n√¥ng nghi·ªáp.")
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []

    for msg in st.session_state.chat_history:
        role = msg["role"]
        content = msg["content"]
        if role=="user":
            st.write(f"**B·∫°n:** {content}")
        else:
            st.write(f"**AI:** {content}")

    user_q = st.text_input("Nh·∫≠p c√¢u h·ªèi", "")
    if st.button("G·ª≠i c√¢u h·ªèi"):
        if user_q.strip():
            st.session_state.chat_history.append({"role":"user","content":user_q})
            try:
                if GEMINI_KEY:
                    model = genai.GenerativeModel("models/gemini-2.5-flash")
                    resp = model.generate_content(user_q)
                    answer = getattr(resp, "text", None) or str(resp)
                else:
                    raise RuntimeError("No GEMINI key")
            except Exception as e:
                answer = f"[Fallback tr·∫£ l·ªùi t·ª± ƒë·ªông] Kh√¥ng th·ªÉ g·ªçi Gemini: {e}"
            st.session_state.chat_history.append({"role":"assistant","content":answer})
